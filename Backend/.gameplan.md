# Plan: LughaBridge Django Real-Time Translation API

This plan builds a production-ready Django Backend with WebSocket support for real-time Kikuyu ↔ English voice translation chat. The architecture supports both live translation (via Google Cloud APIs) and a fully-functional demo mode with mock data for hackathon presentations. The Backend exposes REST and WebSocket endpoints to power the premium Next.js Frontend with chat bubbles, voice input, confidence scores, and real-time message delivery.

**Key Architecture Decisions:**
- **Django Channels + ASGI** for WebSocket real-time chat (industry standard)
- **Google Cloud APIs** for STT/Translation/TTS with Kikuyu support (confirmed language availability)
- **Django-Q** for background tasks (simpler than Celery for initial implementation)
- **Redis** for channel layer, caching, and session management
- **JWT authentication** via djangorestframework-simplejwt (Frontend-friendly, stateless)
- **Service layer pattern** with factory pattern for swappable translation providers (Google/Mock)

**Steps**

## 1. Django Project Initialization & Configuration

**Create project structure:**
- Initialize Django project: `django-admin startproject lughabridge Backend/`
- Create apps: `accounts`, `chat`, `translation`, `api`
- Configure `Backend/lughabridge/settings/base.py`, `development.py`, `production.py`
- Set up `Backend/lughabridge/asgi.py` for ASGI application
- Create `Backend/lughabridge/routing.py` for WebSocket routing

**Install core dependencies in `Backend/requirements/base.txt`:**
```
Django>=4.2
channels>=4.0
channels-redis>=4.1
djangorestframework>=3.14
djangorestframework-simplejwt>=5.3
django-environ>=0.11
django-cors-headers>=4.3
redis>=5.0
django-q>=1.3
```

**Install translation service dependencies:**
```
google-cloud-speech>=2.20
google-cloud-translate>=3.11
google-cloud-texttospeech>=2.14
openai>=1.12
```

**Configure environment variables in `Backend/.env.example`:**
- `SECRET_KEY`, `DEBUG`, `ALLOWED_HOSTS`
- `DATABASE_URL` (PostgreSQL for production, SQLite for dev)
- `REDIS_URL=redis://localhost:6379/0`
- `GOOGLE_APPLICATION_CREDENTIALS` (path to service account JSON)
- `OPENAI_API_KEY` (optional for alternative TTS)
- `FRONTEND_URL=http://localhost:3000` (CORS)

**Configure ASGI and Channels in `settings/base.py`:**
- Set `ASGI_APPLICATION = 'lughabridge.asgi.application'`
- Configure `CHANNEL_LAYERS` with Redis backend
- Add `channels`, `rest_framework`, `corsheaders`, `django_q` to `INSTALLED_APPS`

## 2. Database Models & Migrations

**Create models in `Backend/apps/chat/models.py`:**
- `Conversation`: UUID primary key, participants (ManyToMany to User), source/target languages, created/updated timestamps, `is_demo` flag
- `Message`: UUID, FK to Conversation, sender, original_text, original_language, translated_text, translated_language, stt_confidence, translation_confidence, processing_status (pending/processing/completed/failed), audio URLs (optional), timestamps

**Create models in `Backend/apps/translation/models.py`:**
- `TranslationCache`: source_text_hash, source_language, target_language, translated_text, confidence_score, created_at, hit_count (unique together on hash+languages, indexed)
- `AudioFile`: UUID, file_path, duration, format, created_at, expires_at (for cleanup)
- `APIUsageLog`: service type, provider, user, request/response JSON, cost_estimate, timestamp, success boolean

**Extend User model in `Backend/apps/accounts/models.py`:**
- Extend `AbstractUser` with `preferred_language` (CharField), `voice_preference` (male/female/neutral)

**Generate and run migrations:**
- `python manage.py makemigrations`
- `python manage.py migrate`

## 3. Translation Service Layer (Factory Pattern)

**Create base service interfaces in `Backend/apps/translation/services/base.py`:**
- Abstract base classes: `STTService`, `TranslationService`, `TTSService` with standard methods (`transcribe`, `translate`, `synthesize`)

**Implement Google Cloud services:**
- `Backend/apps/translation/services/google_stt.py`: Use `google.cloud.speech.SpeechClient` for audio → text transcription, return confidence scores
- `Backend/apps/translation/services/google_translate.py`: Use `google.cloud.translate_v2.Client` for Kikuyu ↔ English translation, implement caching via `TranslationCache` model
- `Backend/apps/translation/services/google_tts.py`: Use `google.cloud.texttospeech.TextToSpeechClient` for text → audio with voice customization (gender, pitch, speed)

**Implement mock services for demo mode:**
- `Backend/apps/translation/services/mock_stt.py`: Return predefined Kikuyu/English transcriptions with artificial delays (0.5-1.5s), realistic confidence scores (0.85-0.98)
- `Backend/apps/translation/services/mock_translate.py`: Hardcoded Kikuyu ↔ English phrase pairs (greetings, common sentences), instant response
- `Backend/apps/translation/services/mock_tts.py`: Return sample audio file URLs or base64 encoded mock audio

**Create service factory in `Backend/apps/translation/services/factory.py`:**
- `TranslationServiceFactory.get_stt_service(mode='live')` → returns GoogleSTT or MockSTT based on mode
- `TranslationServiceFactory.get_translation_service(mode='live')` → GoogleTranslate or MockTranslate
- `TranslationServiceFactory.get_tts_service(mode='live')` → GoogleTTS or MockTTS
- Read mode from environment variable `DEMO_MODE=true/false` or per-request parameter

**Implement caching wrapper in `Backend/apps/translation/services/cached_translator.py`:**
- Decorator/wrapper around `TranslationService.translate()` that checks `TranslationCache` model by text hash
- Cache hit: Return cached translation, increment hit_count
- Cache miss: Call underlying service, store in cache with 24-hour TTL in Redis + persistent DB

## 4. WebSocket Consumers for Real-Time Chat

**Create chat consumer in `Backend/apps/chat/consumers.py`:**
- `ChatConsumer(AsyncWebsocketConsumer)`: Handle real-time message flow
  
**Implement connection lifecycle:**
- `connect()`: Authenticate user via JWT from query params, join conversation group (channel layer group), send "connected" status to client
- `disconnect()`: Leave conversation group, log disconnection
- `receive()`: Handle incoming message events: `voice_message`, `text_message`, `read_aloud`, `get_history`

**Message processing flow in `receive_voice_message()`:**
1. Receive base64 audio data from client
2. Trigger Django-Q background task: `process_voice_message_task(conversation_id, sender_id, audio_data, language)`
3. Immediately send "processing" status to client via WebSocket
4. Background task runs translation pipeline (detailed in Step 5)
5. On completion, broadcast translated message to conversation group via channel layer
6. All participants receive message bubble data (original text, translation, confidence, timestamp)

**WebSocket routing in `Backend/apps/chat/routing.py`:**
- `websocket_urlpatterns = [path('ws/chat/<uuid:conversation_id>/', ChatConsumer.as_asgi())]`

**Update project routing in `Backend/lughabridge/routing.py`:**
- Use `ProtocolTypeRouter` and `URLRouter` to route WebSocket connections
- Apply `JWTAuthMiddleware` for WebSocket authentication

## 5. Django-Q Background Tasks for Translation Pipeline

**Create async tasks in `Backend/apps/translation/tasks.py`:**

**Task: `process_voice_message_task(conversation_id, sender_id, audio_data, original_language, mode='live')`**
1. Get service factory instances based on mode (live/demo)
2. **STT**: Transcribe audio → original_text + confidence
3. **Detect target language** from conversation settings (if Kikuyu → English, if English → Kikuyu)
4. **Translate**: original_text → translated_text + confidence (with caching)
5. **TTS**: Generate translated audio (optional, can be done on-demand)
6. **Save**: Create `Message` record with all data, set `processing_status='completed'`
7. **Broadcast**: Send message to WebSocket group via `channel_layer.group_send()`
8. **Log API usage**: Create `APIUsageLog` entry

**Error handling:**
- Try-except blocks around each service call
- On failure: Set `processing_status='failed'`, send error message to WebSocket
- Implement retry logic (Django-Q supports automatic retries)

**Task: `cleanup_expired_audio_files()`**
- Scheduled daily via Django-Q
- Query `AudioFile` where `expires_at < now()`
- Delete files from storage and database records

**Configure Django-Q in `settings/base.py`:**
- Set `Q_CLUSTER` with Redis connection, worker count, timeout settings

## 6. REST API Endpoints (Django REST Framework)

**Create serializers in `Backend/apps/api/v1/chat/serializers.py`:**
- `ConversationSerializer`: Serialize conversation with participants, metadata
- `MessageSerializer`: Serialize message with original/translated text, confidence scores, timestamps
- `CreateConversationSerializer`: Validate conversation creation payload

**Create API views in `Backend/apps/api/v1/chat/views.py`:**

**Endpoints:**
- `POST /api/v1/conversations/` → Create new conversation (participants, languages)
- `GET /api/v1/conversations/` → List user's conversations
- `GET /api/v1/conversations/{uuid}/` → Get conversation details
- `GET /api/v1/conversations/{uuid}/messages/` → Get message history (paginated, ordered by created_at)
- `POST /api/v1/conversations/{uuid}/messages/read-aloud/` → Generate TTS for existing message
- `POST /api/v1/conversations/{uuid}/demo/` → Populate conversation with mock messages for demo mode

**Authentication: Apply `JWTAuthentication` to all views**

**Create user management views in `Backend/apps/api/v1/users/views.py`:**
- `POST /api/v1/auth/register/` → User registration
- `POST /api/v1/auth/login/` → JWT token obtain (using simplejwt)
- `POST /api/v1/auth/refresh/` → JWT token refresh
- `GET /api/v1/users/me/` → Get current user profile
- `PATCH /api/v1/users/me/` → Update preferences (language, voice)

**URL routing in `Backend/apps/api/urls.py`:**
- Include v1 API routes with `/api/v1/` prefix
- Use DRF Routers for ViewSets

## 7. Authentication & Authorization

**Configure JWT in `settings/base.py`:**
```python
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(minutes=15),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': True,
}
```

**Create JWT WebSocket middleware in `Backend/apps/accounts/middleware.py`:**
- Custom middleware to extract JWT from WebSocket query params: `ws://...?token=<jwt>`
- Validate token using `simplejwt` token validation
- Attach `user` to `scope['user']` for consumer access

**Permissions:**
- Ensure users can only access their own conversations
- Verify conversation participants before allowing WebSocket connection
- Rate limiting: 100 messages/hour per user (using `django-ratelimit` or DRF throttling)

## 8. CORS Configuration for Next.js Frontend

**Configure in `settings/base.py`:**
```python
CORS_ALLOWED_ORIGINS = [
    env('FRONTEND_URL', default='http://localhost:3000'),
]
CORS_ALLOW_CREDENTIALS = True
CORS_ALLOW_HEADERS = [
    *default_headers,
    'authorization',
    'sec-websocket-protocol',
]
```

**Add middleware:**
- Place `'corsheaders.middleware.CorsMiddleware'` at top of `MIDDLEWARE` list

## 9. Demo Mode Implementation

**Create demo data fixtures in `Backend/apps/chat/fixtures/demo_conversations.json`:**
- Sample Kikuyu phrases: "Wĩ mwega?" (How are you?), "Nĩ wega, nĩ waku?" (I'm fine, you?)
- English responses with natural conversation flow
- Pre-translated pairs with realistic timestamps

**Demo mode API endpoint:**
- `POST /api/v1/conversations/{uuid}/demo/` → Loads fixture messages into conversation, returns immediately
- Frontend can display these messages with simulated delays

**Service factory demo mode:**
- When `mode='demo'`, all services use mock implementations
- Mock services return instantly with predefined responses
- No external API calls, works offline

**Environment toggle:**
- `DEMO_MODE=true` in `.env` switches entire Backend to demo mode globally
- Per-request override: `?mode=demo` query parameter on API endpoints

## 10. Docker Containerization

**Create `Backend/Dockerfile`:**
- Base image: `python:3.13-slim`
- Install dependencies from `requirements/production.txt`
- Copy Django app code
- Expose port 8000
- CMD: `daphne -b 0.0.0.0 -p 8000 lughabridge.asgi:application`

**Create `Backend/docker-compose.yml`:**
```yaml
services:
  web:
    build: .
    command: daphne -b 0.0.0.0 -p 8000 lughabridge.asgi:application
    ports:
      - "8000:8000"
    env_file: .env
    depends_on:
      - redis
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
  
  worker:
    build: .
    command: python manage.py qcluster
    env_file: .env
    depends_on:
      - redis
```

**For hackathon simplicity:**
- Single container with SQLite database
- In-memory Redis option or shared Redis container

## 11. Error Handling & Logging

**Create custom exceptions in `Backend/apps/core/exceptions.py`:**
- `TranslationServiceError`, `STTServiceError`, `TTSServiceError`, `AudioProcessingError`
- Map to appropriate HTTP status codes

**Configure DRF exception handler in `Backend/apps/core/exception_handlers.py`:**
- Override `rest_framework.views.exception_handler`
- Return consistent format: `{"error": {"code": "...", "message": "...", "details": {}}}`

**Configure logging in `settings/base.py`:**
- Console handler for development
- File handler for production: `logs/django.log`, `logs/translation.log`
- Separate logger for translation services with DEBUG level
- Use JSON formatter (`python-json-logger`) for structured logs

**WebSocket error handling:**
- Send error events to client: `{"type": "error", "code": "TRANSLATION_FAILED", "message": "..."}`
- Don't close connection on recoverable errors
- Close with error code on authentication failures

## 12. Caching Strategy

**Redis caching configuration:**
- Django cache framework with `django-redis` backend
- Cache translation results: Key format `trans:{src_lang}:{tgt_lang}:{hash(text)}`, TTL 24 hours
- Cache TTS audio URLs: Key format `tts:{hash(text)}:{voice}:{lang}`, TTL 1 hour

**Database caching:**
- `TranslationCache` model persists translations permanently
- Updated on every translation (cache miss)
- Queried before hitting external API

**Implement cache-aside pattern in translation service:**
1. Check Redis cache
2. If miss, check DB cache (`TranslationCache`)
3. If miss, call external API
4. Store in both Redis (TTL) and DB (permanent)

## 13. Testing & Validation

**Create test structure:**
- `Backend/apps/translation/tests/test_services.py`: Unit tests for STT/Translation/TTS services with mocked API responses
- `Backend/apps/chat/tests/test_consumers.py`: WebSocket consumer tests using `channels.testing.WebsocketCommunicator`
- `Backend/apps/api/tests/test_views.py`: REST API endpoint tests with pytest-django

**Mock external APIs in tests:**
- Use `unittest.mock` or `responses` library to mock Google Cloud API calls
- Test with demo mode enabled (no external dependencies)

**Run tests:**
- `pytest` with coverage reporting
- CI integration (GitHub Actions)

## 14. Documentation & Deployment Preparation

**Create API documentation:**
- Use DRF's built-in browsable API
- Optional: Add `drf-spectacular` for OpenAPI/Swagger docs at `/api/schema/swagger/`

**Create `Backend/README.md`:**
- Setup instructions (virtualenv, dependencies, environment variables)
- Running locally: `python manage.py runserver` (dev) or `daphne lughabridge.asgi:application` (ASGI)
- Running workers: `python manage.py qcluster`
- Docker instructions: `docker-compose up`
- API endpoint documentation
- WebSocket connection examples

**Environment setup guide:**
- Google Cloud setup: Create project, enable APIs (Speech-to-Text, Translation, Text-to-Speech), download service account JSON
- Redis installation (local or Docker)
- Database setup (migrations)

**Production deployment checklist:**
- Set `DEBUG=False`
- Configure `ALLOWED_HOSTS` and `CSRF_TRUSTED_ORIGINS`
- Use PostgreSQL instead of SQLite
- Set up SSL certificates (Let's Encrypt)
- Configure nginx as reverse proxy
- Set up monitoring (Sentry for errors)
- Configure log rotation

---

## Verification

**Local development testing:**
1. Start Redis: `redis-server`
2. Run migrations: `python manage.py migrate`
3. Create superuser: `python manage.py createsuperuser`
4. Start ASGI server: `daphne -p 8000 lughabridge.asgi:application`
5. Start Django-Q worker: `python manage.py qcluster`
6. Test REST API: `curl http://localhost:8000/api/v1/conversations/` with JWT token
7. Test WebSocket: Connect to `ws://localhost:8000/ws/chat/{uuid}/?token={jwt}` via client

**Demo mode verification:**
1. Set `DEMO_MODE=true` in `.env`
2. Create conversation via API
3. Send voice message via WebSocket
4. Verify instant mock translation response
5. Check that no external API calls are made (check logs)

**Production-like testing:**
1. Build Docker images: `docker-compose build`
2. Start services: `docker-compose up`
3. Verify all containers running (web, redis, worker)
4. Test API endpoints and WebSocket connections
5. Check logs for errors: `docker-compose logs -f`

**Integration with Frontend:**
1. Configure CORS with Next.js dev server URL
2. Frontend connects to `http://localhost:8000/api/`
3. WebSocket connection to `ws://localhost:8000/ws/chat/`
4. Test end-to-end flow: Register → Login → Create conversation → Send voice message → Receive translation

**Performance benchmarks:**
- WebSocket message round-trip: < 100ms (demo mode)
- Translation pipeline latency: 1-3 seconds (live mode with Google APIs)
- Concurrent connections: Support 100+ WebSocket connections on single server
- API response time: < 200ms for REST endpoints

---

## Decisions

**Django Channels vs FastAPI**: Chose Channels for tighter Django integration, mature WebSocket support, and unified codebase (vs maintaining separate Django + FastAPI services)

**Django-Q vs Celery**: Chose Django-Q for initial implementation due to simpler setup, sufficient for hackathon/early production. Can migrate to Celery later if needed for advanced features (workflows, canvas, etc.)

**Google Cloud vs OpenAI/Azure**: Chose Google Cloud as primary provider due to confirmed Kikuyu language support in both Speech and Translation APIs. OpenAI Whisper as self-hosted fallback for STT.

**JWT vs Session Auth**: Chose JWT for stateless authentication, better suited for WebSocket connections and Next.js Frontend, supports mobile apps in future

**Demo mode approach**: Implemented swappable service factory pattern (live vs mock) rather than feature flags, allowing complete offline functionality for hackathon demos without code changes

**Caching strategy**: Multi-layer approach (Redis + DB) balances performance (fast Redis lookups) with persistence (DB for analytics and long-term caching) and cost reduction (minimize API calls)

**Audio storage**: Temporary storage with aggressive cleanup (24-hour expiration) to minimize costs. Production can use S3 with lifecycle policies. For demo mode, optional to skip audio storage entirely and work with text only.
