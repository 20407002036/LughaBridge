# Django settings
SECRET_KEY=your-secret-key-here-change-in-production
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1

# Database (SQLite for dev, can use PostgreSQL in production)
DATABASE_URL=sqlite:///db.sqlite3

# Redis
REDIS_URL=redis://localhost:6379/0

# Frontend CORS
FRONTEND_URL=http://localhost:3000

# Model settings
HF_CACHE_DIR=/tmp/huggingface_cache
HF_TOKEN=  # Required for HF Inference API and Kikuyu translation. Get from https://huggingface.co/settings/tokens
HF_HUB_ENABLE_HF_TRANSFER=0

# Groq API settings (for fast Swahili translation)
GROQ_API_KEY=  # Optional: For faster Swahili translation. Get from https://console.groq.com/keys (free 30 req/min)
GROQ_MODEL=llama-3.3-70b-versatile  # Best for translation. Alternative: llama-3.1-8b-instant (faster)
USE_GROQ_FOR_SWAHILI=True  # Use Groq for Swahili (faster), HF for Kikuyu (better quality)

# Model execution mode (choose one):
# - DEMO_MODE=True: Use mock services with fake responses (for testing/demos, no models needed)
# - USE_HF_INFERENCE=True: Use cloud APIs (Groq + HF hybrid, requires both tokens, works on 512MB RAM)
# - Both False: Use local models (requires 8GB+ RAM and GPU recommended)
# 
# Priority: DEMO_MODE > USE_HF_INFERENCE > Local models
# 
# Hybrid mode (USE_HF_INFERENCE=True):
#   - Swahili ↔ English: Groq (if GROQ_API_KEY set, otherwise HF)
#   - Kikuyu ↔ English: HF NLLB model (trained on Kikuyu)
#   - ASR/TTS: HF Inference API
DEMO_MODE=False
USE_HF_INFERENCE=True  # Recommended for production on Render/similar platforms

# Supported languages (comma-separated)
SUPPORTED_LANGUAGES=kikuyu,swahili,english
